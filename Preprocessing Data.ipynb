{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bllipparser\n",
    "import json\n",
    "import os\n",
    "from nltk.corpus import gutenberg, reuters\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: /Users/kesslej/.local/share/bllipparser/WSJ+Gigaword-v2\n",
      "Model directory already exists, not reinstalling\n"
     ]
    }
   ],
   "source": [
    "rrp = bllipparser.RerankingParser.fetch_and_load('WSJ+Gigaword-v2', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a5c66d75fcf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gutenberg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reuters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "nltk.download('gutenberg')\n",
    "nltk.download('reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def get_sentences_from_dataset(dataset):\n",
    "    data = []\n",
    "    for fileid in dataset.fileids()[:100]:\n",
    "        data.append({'fileid':fileid, 'raw': dataset.raw(fileid)})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def parse_with_corenlp(df, intermediate_file_name = 'raw.txt'):\n",
    "    df['raw'].to_csv(intermediate_file_name, index=Fa)\n",
    "    os.system(('java -cp \"{}/*\" '\n",
    "               '-Xmx500m edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators '\n",
    "               'tokenize,ssplit,pos,parse -file {} -outputFormat json'\n",
    "              ).format(CORENLP_PATH, intermediate_file_name))\n",
    "    \n",
    "def get_treelist(intermediate_file_name = 'raw.txt'):\n",
    "    trees = []\n",
    "    for l in list(open(intermediate_file_name + '.json')):\n",
    "        l = l.strip()\n",
    "        if l.startswith('\"parse\":'):\n",
    "            trees.append(' '.join(json.loads('{'+l[:-1]+'}')['parse'].split()))\n",
    "    return pd.DataFrame({'tree': trees})\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time\n",
    "#df = get_sentences_from_dataset(reuters)\n",
    "#parse_with_corenlp(df)\n",
    "get_treelist().to_csv('trees.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iter_top_nps(tree):\n",
    "    if isinstance(tree, Tree):\n",
    "        if tree.label() == 'NP':\n",
    "            yield tree\n",
    "        else:\n",
    "            for subtree in tree:\n",
    "                for tree in iter_top_nps(subtree):\n",
    "                    yield tree\n",
    "                    \n",
    "def get_numbers_from_tree(tree):\n",
    "    for subtree in tree:\n",
    "        if subtree.label() == 'NP':\n",
    "            #print('examining', ' '.join(subtree.leaves()))\n",
    "            labels = [subtree.label() for subtree in tree if subtree.label() not in (',', 'CC')]\n",
    "            #print('labels', labels, len(set(labels)) == 1 and labels[0] == 'NP')\n",
    "            if len(set(labels)) == 1 and labels[0] == 'NP':\n",
    "                for subtree in tree:\n",
    "                    if subtree.label() == 'NP':\n",
    "                        for subsubtree in iter_top_nps(subtree):\n",
    "                            yield get_number_from_np(subtree)\n",
    "            else:\n",
    "                #print('returning', tree)\n",
    "                yield get_number_from_np(subtree)\n",
    "\n",
    "def get_number_from_np(tree):\n",
    "    pos_list = [pos for orth, pos in tree.pos()]\n",
    "    if pos_list[-1][-1] == 'S' or 'CC' in pos_list:\n",
    "        return 'P'\n",
    "    return 'S'\n",
    "\n",
    "def which_is_more_ambiguous(numbers):\n",
    "    if numbers[-3:] == ['S', 'S', 'S']: return 'Oxford' # my mother, Jill, and Sam\n",
    "    if numbers[-3:] == ['S', 'S', 'P']: return 'Oxford' # my mother, Jill, and the Smiths\n",
    "    if numbers[-3:] == ['S', 'P', 'S']: return 'Neither' # my mother, the Smiths, and Sam\n",
    "    if numbers[-3:] == ['S', 'P', 'P']: return 'Neither' # my mother, the Smiths, and the Jonese\n",
    "    if numbers[-3:] == ['P', 'S', 'S']: return 'Lack of Oxford' # my parents, Jill and Sam\n",
    "    if numbers[-3:] == ['P', 'P', 'S']: return 'Lack of Oxford' # my family, the Smiths and Sam\n",
    "    if numbers[-3:] == ['P', 'S', 'P']: return 'Lack of Oxford' # my family, Sam and the Smiths\n",
    "    if numbers[-3:] == ['P', 'P', 'P']: return 'Lack of Oxford' # my family, the Smiths and the Joneses\n",
    "        \n",
    "def analyze_tree(tree):\n",
    "    for np in iter_top_nps(tree):\n",
    "        numbers = list(get_numbers_from_tree(np))\n",
    "        if len(numbers) > 2:\n",
    "            yield [np, numbers, which_is_more_ambiguous(numbers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NP', ['NNP', 'NNP']], [',', []], ['NP', ['NP', 'PP']]]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = Tree.fromstring('''(NP\n",
    "  (NP (NNP Tom) (NNP Murtha))\n",
    "  (, ,)\n",
    "  (NP\n",
    "    (NP (DT a) (NN stock) (NN analyst))\n",
    "    (PP\n",
    "      (IN at)\n",
    "      (NP\n",
    "        (NP (DT the) (NNP Tokyo) (NN office))\n",
    "        (PP (IN of) (NP (NN broker)))))))''')\n",
    "[[t.label(), [e.label() for e in t if type(e) == Tree]] for t in tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 , `` ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RIFT Mounting trade friction between the U.S. And Japan has raised fears among many of Asia 's exporting nations that the row could inflict far-reaching economic damage , businessmen and officials\n",
      "[['S', 'P', 'S', 'P'], 'Lack of Oxford']\n",
      "firm Matsushita Electric Industrial Co Ltd < MC.T >\n",
      "[['S', 'S', 'S', 'S'], 'Oxford']\n",
      "Tom Murtha , a stock analyst at the Tokyo office of broker\n",
      "[['S', 'S', 'S', 'S'], 'Oxford']\n",
      "the world 's largest\n",
      "[['P', 'P', 'P', 'P'], 'Lack of Oxford']\n",
      "Paul Sheen , chairman of textile exporters\n",
      "[['S', 'P', 'S', 'P'], 'Lack of Oxford']\n",
      "the U.S. , Up from 4.9 billion dlrs in 1985\n",
      "[['S', 'S', 'S', 'S'], 'Oxford']\n",
      "coal and beef , Australia 's two largest exports\n",
      "[['P', 'P', 'P', 'P'], 'Lack of Oxford']\n",
      "Deputy U.S. Trade Representative Michael Smith and Makoto Kuroda , Japan 's deputy minister of International Trade and Industry -LRB- MITI -RRB- ,\n",
      "[['P', 'P', 'P', 'P'], 'Lack of Oxford']\n",
      "improved technology in storage and preservation , and greater production of additives\n",
      "[['P', 'P', 'P', 'P'], 'Lack of Oxford']\n"
     ]
    }
   ],
   "source": [
    "for tree in get_treelist()['tree'].iloc[:40]:\n",
    "    for x in analyze_tree(Tree.fromstring(tree)):\n",
    "        print(' '.join(x[0].leaves()))\n",
    "        print(x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
